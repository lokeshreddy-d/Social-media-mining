{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "aeIdAlHwuHwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib, os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import google.generativeai as genai\n",
        "\n",
        "from time import sleep\n",
        "\n",
        "# Used to securely store my API key\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "fO4O3qBvyO59"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# List of Models"
      ],
      "metadata": {
        "id": "vkU8L2BK3iRS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   gemini-pro: optimized for text-only prompts.\n",
        "*   gemini-pro-vision: optimized for text-and-images prompts.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mvoh0iCny0A5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def list_genai_models():\n",
        "    for m in genai.list_models():\n",
        "        if 'generateContent' in m.supported_generation_methods:\n",
        "            print(m.name)\n",
        "\n",
        "list_genai_models()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "HRdDnpm53XAT",
        "outputId": "1ce3d7f3-4fd2-4fc9-eff9-36fa7af91bae"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# All Defined Functions"
      ],
      "metadata": {
        "id": "2XuhLTW58MDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file_as_string(filename):\n",
        "  with open(filename, \"r\") as f:\n",
        "    content = f.read()\n",
        "  return content\n",
        "\n",
        "def generate_response(prompt, text):\n",
        "    response = model.generate_content([prompt, text])\n",
        "    text_content = response.candidates[0].content.parts[0].text\n",
        "\n",
        "    return text_content\n",
        "\n",
        "def parse_predictions(response):\n",
        "    # Split the string into pairs of 'label = value'\n",
        "    pairs = response.split(\"\\n\")\n",
        "    predictions_dict = {}\n",
        "\n",
        "    for pair in pairs:\n",
        "        if pair:  # This checks if the pair is not empty\n",
        "            # Split each pair into label and value, then strip whitespace and remove the '='\n",
        "            label, value = pair.split(\"=\")\n",
        "            label = label.strip()\n",
        "            value = value.strip()\n",
        "            predictions_dict[label] = int(value)  # Convert the value to integer\n",
        "\n",
        "    return predictions_dict"
      ],
      "metadata": {
        "id": "OiB9lPJwoPdA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification"
      ],
      "metadata": {
        "id": "7e5R-CRQ8USa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "id": "scIZS1mBxu_L",
        "outputId": "6a4aebbe-f170-4963-a986-818f509c51df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index: 0\n",
            "Text: havent quite reached technological singularity yet incorrect yet convincing answers ai still incorrect therefore useless chatgpt\n",
            "toxic = 0\n",
            "\n",
            "Index: 0\n",
            "Text: havent quite reached technological singularity yet incorrect yet convincing answers ai still incorrect therefore useless chatgpt\n",
            "severe_toxic = 0\n",
            "\n",
            "Index: 0\n",
            "Text: havent quite reached technological singularity yet incorrect yet convincing answers ai still incorrect therefore useless chatgpt\n",
            "obscene = 0\n",
            "\n",
            "Index: 0\n",
            "need to input data for threat\n",
            "\n",
            "Index: 0\n",
            "Text: havent quite reached technological singularity yet incorrect yet convincing answers ai still incorrect therefore useless chatgpt\n",
            "insult = 1\n",
            "\n",
            "Index: 0\n",
            "Text: havent quite reached technological singularity yet incorrect yet convincing answers ai still incorrect therefore useless chatgpt\n",
            "identity_hate = 0\n",
            "\n",
            "Index: 1\n",
            "Text: chatgpt like donald trump convincing bullshit times even true\n",
            "toxic = 0\n",
            "\n",
            "Index: 1\n",
            "Text: chatgpt like donald trump convincing bullshit times even true\n",
            "severe_toxic = 1\n",
            "\n",
            "Index: 1\n",
            "Text: chatgpt like donald trump convincing bullshit times even true\n",
            "obscene = 0\n",
            "\n",
            "Index: 1\n",
            "need to input data for threat\n",
            "\n",
            "Index: 1\n",
            "Text: chatgpt like donald trump convincing bullshit times even true\n",
            "insult = 1\n",
            "\n",
            "Index: 1\n",
            "Text: chatgpt like donald trump convincing bullshit times even true\n",
            "identity_hate = 0\n",
            "\n",
            "Index: 2\n",
            "Text: holy fucking shit chatgpt one example incredible tools developed field ai tools potential improve humanity species ways cant even fucking imagine yet ai chatgpt humanenhancement\n",
            "toxic = 0\n",
            "\n",
            "Index: 2\n",
            "Text: holy fucking shit chatgpt one example incredible tools developed field ai tools potential improve humanity species ways cant even fucking imagine yet ai chatgpt humanenhancement\n",
            "severe_toxic = 1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load model\n",
        "model = genai.GenerativeModel('gemini-1.0-pro-latest')\n",
        "\n",
        "# Load data from CSV file\n",
        "dataset = pd.read_csv('/content/test_toxic_dataset_without_label.csv')\n",
        "results = []\n",
        "classes = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "\n",
        "max_retries = 5  # Maximum number of retries\n",
        "wait_time = 60  # Waiting time in seconds between retries\n",
        "\n",
        "for ind, data in dataset.iterrows():\n",
        "  for i in range(1, 7):\n",
        "    prompt = read_file_as_string(f\"/content/prompt{i}\")\n",
        "    for attempt in range(max_retries + 1):\n",
        "      try:\n",
        "        response = generate_response(prompt, data['processed_text'])\n",
        "\n",
        "        print(f\"Index: {ind}\\nText: {data['processed_text']}\\n{response}\\n\")\n",
        "        predictions = parse_predictions(response)\n",
        "\n",
        "        for label, value in predictions.items():\n",
        "            data[label] = value\n",
        "\n",
        "        #results.append(data)\n",
        "        break  # Successful response, exit loop\n",
        "      except Exception as e:\n",
        "        #print('Exception occurred:', e)\n",
        "        if \"429\" in str(e):\n",
        "          if attempt == max_retries:\n",
        "            print(f\"Error: Reached maximum retries for index: {ind}\")\n",
        "          else:\n",
        "            print(f\"Warning: Too many requests (attempt {attempt+1}/{max_retries}). Waiting {wait_time} seconds...\")\n",
        "            sleep(wait_time)  # Wait before retrying\n",
        "        else: break\n",
        "\n",
        "    if np.isnan(data[classes[i-1]]):\n",
        "      print(f\"Index: {ind}\\nneed to input data for {classes[i-1]}\\n\")\n",
        "      data[classes[i-1]] = -1\n",
        "  results.append(data)\n",
        "\n",
        "# Compile results into a DataFrame\n",
        "result_df = pd.DataFrame(results)\n",
        "\n",
        "# Save the result to a new CSV file\n",
        "result_df.to_csv(f'labeled_dataset.csv', index=False, encoding='utf-8')\n",
        "#####################################################################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classifying Again To Get Response for The Missed One"
      ],
      "metadata": {
        "id": "w63oHWQg86qm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data from CSV file\n",
        "dataset = pd.read_csv('/content/labeled_dataset.csv')\n",
        "results = []\n",
        "classes = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "\n",
        "max_retries = 5  # Maximum number of retries\n",
        "wait_time = 60  # Waiting time in seconds between retries\n",
        "\n",
        "for ind, data in dataset.iterrows():\n",
        "  for i in range(1, 7):\n",
        "    prompt = read_file_as_string(f\"/content/prompt{i}\")\n",
        "    if data[classes[i-1]] == 0 or data[classes[i-1]] == -1:\n",
        "      print(f\"prev response: {classes[i-1]} = {data[classes[i-1]]}\")\n",
        "      for attempt in range(max_retries + 1):\n",
        "        try:\n",
        "          response = generate_response(prompt, data['processed_text'])\n",
        "\n",
        "          print(f\"Index: {ind}\\nText: {data['processed_text']}\\n{response}\\n\")\n",
        "          predictions = parse_predictions(response)\n",
        "\n",
        "          for label, value in predictions.items():\n",
        "              data[label] = value\n",
        "\n",
        "          #results.append(data)\n",
        "          break  # Successful response, exit loop\n",
        "        except Exception as e:\n",
        "          #print('Exception occurred:', e)\n",
        "          if \"429\" in str(e):\n",
        "            if attempt == max_retries:\n",
        "              print(f\"Error: Reached maximum retries for index: {ind}\")\n",
        "            else:\n",
        "              print(f\"Warning: Too many requests (attempt {attempt+1}/{max_retries}). Waiting {wait_time} seconds...\")\n",
        "              sleep(wait_time)  # Wait before retrying\n",
        "          else: break\n",
        "\n",
        "      # if np.isnan(data[classes[i-1]]):\n",
        "      #   print(f\"Index: {ind}\\nneed to input data for {classes[i-1]}\\n\")\n",
        "      #   data[classes[i-1]] = -1\n",
        "  results.append(data)\n",
        "\n",
        "# Compile results into a DataFrame\n",
        "result_df = pd.DataFrame(results)\n",
        "\n",
        "# Save the result to a new CSV file\n",
        "result_df.to_csv(f'gemini_response.csv', index=False, encoding='utf-8')\n",
        "#####################################################################################################################"
      ],
      "metadata": {
        "id": "wKuYPzD39Bz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deleting Invalid Response"
      ],
      "metadata": {
        "id": "g77Cw1NNBibw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data from the CSV files\n",
        "df1 = pd.read_csv('/content/test_toxic_dataset.csv')\n",
        "df2 = pd.read_csv('/content/gemini_response.csv')\n",
        "\n",
        "# Select the columns to add from the first DataFrame\n",
        "# Assuming the columns are named 'Column1', 'Column2', ..., 'Column6'\n",
        "columns_to_add = df1[classes]\n",
        "\n",
        "# Rename the selected columns\n",
        "columns_to_add.columns = ['true_' + col for col in columns_to_add.columns]\n",
        "\n",
        "# Concatenate the renamed columns to the second DataFrame\n",
        "df2 = pd.concat([df2, columns_to_add], axis=1)\n",
        "\n",
        "# Save the updated DataFrame back to a CSV file\n",
        "df2.to_csv('gemini_response_final.csv', index=False)\n"
      ],
      "metadata": {
        "id": "DhaNQxGeBcRj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}